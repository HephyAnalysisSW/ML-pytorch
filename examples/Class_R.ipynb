{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe54142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ZH_Nakamura\n",
    "import subprocess\n",
    "import os\n",
    "torch.set_default_dtype(torch.float64)\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Tools import syncer \n",
    "from Tools import user\n",
    "from Tools import helpers\n",
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d2ff07-baf1-4bc5-a3a7-7e69d51b5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weight_ratio(r, weights, base_points):\n",
    "    weight_ratio=0\n",
    "    nCoefficients=len(r.coefficient_names)\n",
    "    row,column=np.triu_indices(nCoefficients+1)\n",
    "    i, j = np.triu_indices(8)                                                                                       \n",
    "    for i_comb, combination in enumerate(r.combination_list):\n",
    "        weight_ratio+=torch.outer(torch.from_numpy(weights[r.combination_list[i_comb]]/weights[()]),(base_points[:,row[i_comb]]*base_points[:,column[i_comb]]))\n",
    "    return weight_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fe76ec-6005-4120-9a6d-a44df20615bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loss(r,features,base_points,weights):\n",
    "        fhat = 1./(1. + r.predict_r_hat(features,base_points))\n",
    "        weight_ratios=make_weight_ratio(r, weights, base_points)\n",
    "        loss = (torch.from_numpy(weights[()])*torch.transpose(weight_ratios*fhat**2 + (1-fhat)**2,0,1)).sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0aab83-ba17-4988-a287-8d8e2aafcc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class R:\n",
    "    def __init__(self,nfeatures,coefficient_names):\n",
    "        self.nfeatures         = nfeatures\n",
    "        self.coefficient_names = coefficient_names\n",
    "        self.combination_list=list(itertools.chain.from_iterable(itertools.combinations_with_replacement(self.coefficient_names, i) for i in np.arange(0,3)))\n",
    "        self.n_hat = {combination: self.make_NN() for combination in self.combination_list}\n",
    "        \n",
    "    def make_NN(self, hidden_layers  = [32, 32, 32, 32]):\n",
    "        '''\n",
    "        Creates the Neural Network Architecture\n",
    "        '''\n",
    "        model_nn = [torch.nn.BatchNorm1d(self.nfeatures), torch.nn.ReLU(), torch.nn.Linear(self.nfeatures, hidden_layers[0])]\n",
    "        for i_layer, layer in enumerate(hidden_layers):\n",
    "            model_nn.append(torch.nn.Linear(hidden_layers[i_layer], hidden_layers[i_layer+1] if i_layer+1<len(hidden_layers) else 1))\n",
    "            if i_layer+1<len(hidden_layers):\n",
    "                model_nn.append( torch.nn.ReLU() )\n",
    "        return torch.nn.Sequential(*model_nn)\n",
    "\n",
    "    def evaluate_NN(self, features):\n",
    "        '''Evaluate Neural Network: The zeroth dimension of features is the number of data points and and the first dimension\n",
    "        is the number of features(variables). Returns the output of the NNs of dimensions: (noutput,ndatapoints)\n",
    "        '''\n",
    "        noutputs=len(self.combination_list)\n",
    "        ndatapoints=features.shape[0]\n",
    "        \n",
    "        output=torch.zeros((noutputs,ndatapoints))\n",
    "        for i in range(noutputs):\n",
    "            x=self.n_hat[self.combination_list[i]](features)\n",
    "            if i==0:\n",
    "                output[i,:]=1\n",
    "            else:\n",
    "                output[i,:]=torch.flatten(x)            \n",
    "        return output\n",
    "        \n",
    "    \n",
    "    def predict_r_hat(self, features, base_points):\n",
    "        '''\n",
    "        Evaluate positive xsec ratio for given theta and.\n",
    "        First it fills the coefficients of the matrix containing the upper cholesky decomposition.\n",
    "        Then it computes the multiplication of this matrix with the basepoints and squares it and sums it.\n",
    "        '''\n",
    "        ndatapoints=features.shape[0]\n",
    "        output_NN = self.evaluate_NN(features)\n",
    "        n_terms=len(self.coefficient_names)\n",
    "        row,column=np.triu_indices(n_terms+1)\n",
    "        Omega=torch.zeros((n_terms+1,n_terms+1,ndatapoints))\n",
    "        for i in range(0, len(row)):\n",
    "            Omega[row[i]][column[i]][:]=output_NN[i,:]\n",
    "        Omega_swapped=torch.swapaxes(Omega,1,2)\n",
    "        Omega_swapped=torch.swapaxes(Omega_swapped,0,1)\n",
    "        \n",
    "        \n",
    "        out=torch.matmul(Omega_swapped,torch.transpose(base_points,0,1))\n",
    "        return torch.linalg.norm(out, 2, 1)\n",
    "    \n",
    "    def save(self,fileName):\n",
    "        outfile = open(fileName,'wb')\n",
    "        pickle.dump(self, outfile)\n",
    "        outfile.close()\n",
    "        \n",
    "    @classmethod\n",
    "    def load(self, fileName):\n",
    "        infile = open(fileName,'rb')\n",
    "        print(fileName)\n",
    "        new_dict = pickle.load(infile)\n",
    "        infile.close()\n",
    "        return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f05cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2)\n"
     ]
    }
   ],
   "source": [
    "n_features=6\n",
    "#coefficients=['cHQ3', 'cHW', 'cHWtil']\n",
    "#base_points = np.asarray([np.array([1, value1, value2, value3]) for value1 in [-1.5, -.8, .2, 0., .2, .8, 1.5]  for value2 in [-1.5, -.8, .2, 0, .2, .8, 1.5] for value3 in [-1.5, -.8, .2, 0, .2, .8, 1.5]])\n",
    "#coefficients=['cHW', 'cHWtil']\n",
    "#base_points = np.asarray([np.array([1, value1, value2]) for value1 in [-1.5, -.8, .2, 0., .2, .8, 1.5]  for value2 in [-1.5, -.8, .2, 0, .2, .8, 1.5]])\n",
    "coefficients=['cHQ3']\n",
    "base_points = np.asarray([np.array([1, value1]) for value1 in [-1.5, -.8, .2, 0., .2, .8, 1.5]])\n",
    "print(base_points.shape)\n",
    "r_NN = R(n_features, coefficients)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8e3dc7-f2ba-4849-9d50-1bf07fa46b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_directory=\"8_7_2022\"\n",
    "\n",
    "nEvents=30000\n",
    "learning_rate = 1e-3\n",
    "device        = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_epoch       = 10000\n",
    "plot_every    = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a181dfe7-810d-4711-a6cd-2bdc69654ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested 30000 events. Simulated 30000 events and 30000 survive pT_min cut of 0.\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "import ZH_Nakamura \n",
    "ZH_Nakamura.feature_names = ZH_Nakamura.feature_names[0:6] # restrict features\n",
    "features   = ZH_Nakamura.getEvents(nEvents)[:,0:6]\n",
    "feature_names  = ZH_Nakamura.feature_names\n",
    "plot_options   = ZH_Nakamura.plot_options\n",
    "plot_vars      = ZH_Nakamura.feature_names\n",
    "\n",
    "mask       = (features[:,feature_names.index('pT')]<900) & (features[:,feature_names.index('sqrt_s_hat')]<1800) \n",
    "features = features[mask]\n",
    "\n",
    "n_features = len(features[0])\n",
    "weights    = ZH_Nakamura.getWeights(features, ZH_Nakamura.make_eft())\n",
    "\n",
    "\n",
    "WC='cHQ3'\n",
    "\n",
    "pT=features[:,feature_names.index('pT')]\n",
    "features=torch.from_numpy(features)\n",
    "w0_train       = torch.from_numpy(weights[()]).float().to(device)\n",
    "wp_train       = torch.from_numpy(weights[(WC,)]).float().to(device)\n",
    "wpp_train      = torch.from_numpy(weights[(WC,WC)]).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42481a4e-fa28-4a93-b413-2d085ac01cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params=[]\n",
    "for comb in r_NN.combination_list:\n",
    "        all_params+=r_NN.n_hat[comb].parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79bce9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(list(all_params), lr=learning_rate)\n",
    "losses = []\n",
    "losses_train=[]\n",
    "for comb in r_NN.combination_list:\n",
    "    r_NN.n_hat[comb].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae5c4fdd-210e-4204-88ef-d80cc62630f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex = ROOT.TLatex()\n",
    "tex.SetNDC()\n",
    "tex.SetTextSize(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0984cc6-b355-4e3e-bec0-3020b124d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.1084],\n",
      "        [ 0.0000, -0.0922]], grad_fn=<SelectBackward0>)\n",
      "epoch  99 loss  2.1364564008129165\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n",
      "Omega\n",
      "tensor([[ 1.0000,  0.0958],\n",
      "        [ 0.0000, -0.1081]], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epoch):\n\u001b[0;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mf_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_NN\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_points\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m99\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss \u001b[39m\u001b[38;5;124m\"\u001b[39m,  loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mf_loss\u001b[0;34m(r, features, base_points, weights)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_loss\u001b[39m(r,features,base_points,weights):\n\u001b[0;32m----> 2\u001b[0m         fhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_r_hat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_points\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m         weight_ratios\u001b[38;5;241m=\u001b[39mmake_weight_ratio(r, weights, base_points)\n\u001b[1;32m      4\u001b[0m         loss \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mfrom_numpy(weights[()])\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtranspose(weight_ratios\u001b[38;5;241m*\u001b[39mfhat\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mfhat)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mR.predict_r_hat\u001b[0;34m(self, features, base_points)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#print(out.shape)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(Omega[:,:,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_sqrt_s_hat.png has been created\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_sqrt_s_hat.png has been created\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_pT.png has been created\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_pT.png has been created\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_y.png has been created\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_y.png has been created\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_cos_theta.png has been created\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_cos_theta.png has been created\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_phi_hat.png has been created\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_phi_hat.png has been created\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: h (Potential memory leak).\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_cos_theta_hat.png has been created\n",
      "Info in <TCanvas::Print>: png file 8_7_2022/epoch_00099_cos_theta_hat.png has been created\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    loss = f_loss(r_NN,features,torch.from_numpy(base_points),weights)\n",
    "    if epoch % 100 == 99:\n",
    "        print(\"epoch \", epoch, \"loss \",  loss.item())\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions=r_NN.evaluate_NN(features)\n",
    "            pred_t = predictions[1].squeeze().cpu().detach().numpy()\n",
    "            pred_s = predictions[2].squeeze().cpu().detach().numpy()\n",
    "\n",
    "            \n",
    "            #loss_train = f_loss(w0_train, wp_train ,wpp_train, pred_t, pred_s)\n",
    "            #losses_train.append(loss_train.item())\n",
    "\n",
    "            \n",
    "            #print(\"epoch \", epoch, \"loss \",  loss_train.item())\n",
    "            \n",
    "            for var in plot_vars:\n",
    "                binning     = plot_options[var]['binning']\n",
    "                np_binning  = np.linspace(binning[1], binning[2], 1+binning[0])\n",
    "\n",
    "                truth_0  = np.histogram(features[:,feature_names.index(var)], np_binning, weights=w0_train )\n",
    "                truth_p  = np.histogram(features[:,feature_names.index(var)], np_binning, weights=wp_train )\n",
    "                truth_pp = np.histogram(features[:,feature_names.index(var)], np_binning, weights=wpp_train )\n",
    "\n",
    "                pred_0  = np.histogram(features[:,feature_names.index(var)], np_binning, weights=w0_train)\n",
    "                pred_p  = np.histogram(features[:,feature_names.index(var)], np_binning, weights=w0_train*2*pred_t)\n",
    "                pred_pp = np.histogram(features[:,feature_names.index(var)], np_binning, weights=w0_train*2*(pred_t**2+pred_s**2) )\n",
    "\n",
    "                h_yield       = helpers.make_TH1F(truth_0)\n",
    "                h_truth_p     = helpers.make_TH1F(truth_p)\n",
    "                h_truth_p     .Divide(h_yield) \n",
    "                h_truth_pp    = helpers.make_TH1F(truth_pp)\n",
    "                h_truth_pp    .Divide(h_yield) \n",
    "\n",
    "                h_pred_p      = helpers.make_TH1F(pred_p)\n",
    "                h_pred_p      .Divide(h_yield) \n",
    "                h_pred_pp     = helpers.make_TH1F(pred_pp)\n",
    "                h_pred_pp     .Divide(h_yield) \n",
    "\n",
    "                l = ROOT.TLegend(0.3,0.7,0.9,0.95)\n",
    "                l.SetNColumns(2)\n",
    "                l.SetFillStyle(0)\n",
    "                l.SetShadowColor(ROOT.kWhite)\n",
    "                l.SetBorderSize(0)\n",
    "\n",
    "                h_yield      .SetLineColor(ROOT.kGray+2) \n",
    "                h_truth_p    .SetLineColor(ROOT.kBlue) \n",
    "                h_truth_pp   .SetLineColor(ROOT.kRed) \n",
    "                h_pred_p     .SetLineColor(ROOT.kBlue) \n",
    "                h_pred_pp    .SetLineColor(ROOT.kRed) \n",
    "                h_yield      .SetMarkerColor(ROOT.kGray+2) \n",
    "                h_truth_p    .SetMarkerColor(ROOT.kBlue) \n",
    "                h_truth_pp   .SetMarkerColor(ROOT.kRed) \n",
    "                h_pred_p     .SetMarkerColor(ROOT.kBlue) \n",
    "                h_pred_pp    .SetMarkerColor(ROOT.kRed) \n",
    "                h_yield      .SetMarkerStyle(0)\n",
    "                h_truth_p    .SetMarkerStyle(0)\n",
    "                h_truth_pp   .SetMarkerStyle(0)\n",
    "                h_pred_p     .SetMarkerStyle(0)\n",
    "                h_pred_pp    .SetMarkerStyle(0)\n",
    "\n",
    "                l.AddEntry(h_truth_p   , \"1^{st.} der (truth)\" ) \n",
    "                l.AddEntry(h_truth_pp  , \"2^{st.} der (truth)\" ) \n",
    "                l.AddEntry(h_pred_p    , \"1^{st.} der (pred)\" ) \n",
    "                l.AddEntry(h_pred_pp   , \"2^{st.} der (pred)\" ) \n",
    "                l.AddEntry(h_yield     , \"yield\" ) \n",
    "\n",
    "                h_truth_p    .SetLineStyle(ROOT.kDashed) \n",
    "                h_truth_pp   .SetLineStyle(ROOT.kDashed)\n",
    "\n",
    "                lines = [ \n",
    "                        (0.16, 0.965, 'Epoch %5i    Loss %6.4f'%( epoch, loss ))\n",
    "                        ]\n",
    "\n",
    "                max_ = max( map( lambda h:h.GetMaximum(), [ h_truth_p, h_truth_pp ] ))\n",
    "\n",
    "                h_yield.Scale(max_/h_yield.GetMaximum())\n",
    "                for logY in [True, False]:\n",
    "                    c1 = ROOT.TCanvas()\n",
    "                    h_yield   .Draw(\"hist\")\n",
    "                    h_yield   .GetYaxis().SetRangeUser(0.1 if logY else 0, 10**(1.5)*max_ if logY else 1.5*max_)\n",
    "                    h_yield   .Draw(\"hist\")\n",
    "                    h_truth_p .Draw(\"hsame\") \n",
    "                    h_truth_pp.Draw(\"hsame\")\n",
    "                    h_pred_p  .Draw(\"hsame\") \n",
    "                    h_pred_pp .Draw(\"hsame\")\n",
    "                    c1.SetLogy(logY) \n",
    "                    l.Draw()\n",
    "\n",
    "                    drawObjects = [ tex.DrawLatex(*line) for line in lines ]\n",
    "                    for o in drawObjects:\n",
    "                        o.Draw()\n",
    "\n",
    "                    plot_directory_final = os.path.join(plot_directory, \"log\" if logY else \"lin\")\n",
    "                    helpers.copyIndexPHP( plot_directory )\n",
    "                    c1.Print( os.path.join( plot_directory, \"epoch_%05i_%s.png\"%(epoch, var) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b2703-420b-4525-a7d7-35d349b0c1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-ptur]",
   "language": "python",
   "name": "conda-env-conda-ptur-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
