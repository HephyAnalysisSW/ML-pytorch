{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe54142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ZH_Nakamura\n",
    "from Class_R import R\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d2ff07-baf1-4bc5-a3a7-7e69d51b5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weight_ratio(r, weights, base_points):\n",
    "    output=0\n",
    "    nCoefficients=len(r.coefficient_names)\n",
    "    row,column=np.triu_indices(nCoefficients+1)\n",
    "    for i_comb, combination in enumerate(r.combination_list):\n",
    "        if row[i_comb]==column[i_comb]:\n",
    "            factor=1\n",
    "        else:\n",
    "            factor=1\n",
    "        output += torch.outer(torch.from_numpy(weights[combination]/weights[()]), factor*base_points[:,row[i_comb]]*base_points[:,column[i_comb]])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25fe76ec-6005-4120-9a6d-a44df20615bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loss(r,features,base_points,weights):\n",
    "        fhat = 1./(1. + r.predict_r_hat(features,base_points))\n",
    "        weight_ratios=make_weight_ratio(r, weights, base_points)\n",
    "        loss = (torch.from_numpy(weights[()])*torch.transpose(weight_ratios*fhat**2 + (1-fhat)**2,0,1)).sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea0aab83-ba17-4988-a287-8d8e2aafcc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class R:\n",
    "    def __init__(self,nfeatures,coefficient_names):\n",
    "        self.nfeatures         = nfeatures\n",
    "        self.coefficient_names = coefficient_names\n",
    "        self.combination_list=list(itertools.chain.from_iterable(itertools.combinations_with_replacement(self.coefficient_names, i) for i in np.arange(0,3)))\n",
    "        self.n_hat = {combination: self.make_NN() for combination in self.combination_list}\n",
    "        \n",
    "    def make_NN(self, hidden_layers  = [32, 32, 32, 32]):\n",
    "        model_nn = [torch.nn.BatchNorm1d(self.nfeatures), torch.nn.ReLU(), torch.nn.Linear(self.nfeatures, hidden_layers[0])]\n",
    "        for i_layer, layer in enumerate(hidden_layers):\n",
    "            model_nn.append(torch.nn.Linear(hidden_layers[i_layer], hidden_layers[i_layer+1] if i_layer+1<len(hidden_layers) else 1))\n",
    "            if i_layer+1<len(hidden_layers):\n",
    "                model_nn.append( torch.nn.ReLU() )\n",
    "        return torch.nn.Sequential(*model_nn)\n",
    "\n",
    "    def evaluate_NN(self, features):\n",
    "        '''Evaluate Neural Network: The zeroth dimension of features is the number of data points and and the first dimension\n",
    "        is the number of features(variables)\n",
    "        '''\n",
    "        noutputs=len(self.combination_list)\n",
    "        ndatapoints=features.shape[0]\n",
    "        \n",
    "        output=torch.zeros((noutputs,ndatapoints))\n",
    "        for i in range(noutputs):\n",
    "            #self.n_hat[self.combination_list[i]].eval()\n",
    "            x=self.n_hat[self.combination_list[i]](features)\n",
    "            if i==0:\n",
    "                output[i,:]=1\n",
    "            else:\n",
    "                output[i,:]=torch.flatten(x)            \n",
    "        return output\n",
    "        \n",
    "    \n",
    "    def predict_r_hat(self, features, theta):\n",
    "        '''Evaluate positive xsec ratio for given theta and \n",
    "        '''\n",
    "        ndatapoints=features.shape[0]\n",
    "        output_NN = self.evaluate_NN(features)\n",
    "        n_terms=len(self.coefficient_names)\n",
    "        row,column=np.triu_indices(n_terms+1)\n",
    "        Omega=torch.zeros((n_terms+1,n_terms+1,ndatapoints))\n",
    "        for i in range(0, len(row)):\n",
    "            Omega[row[i]][column[i]][:]=output_NN[i,:]\n",
    "        Omega_swapped=torch.swapaxes(Omega,1,2)\n",
    "        Omega_swapped=torch.swapaxes(Omega_swapped,0,1)\n",
    "        \n",
    "        out=torch.matmul(Omega_swapped,torch.transpose(theta,0,1))\n",
    "        return torch.linalg.norm(out, 2, 1)\n",
    "    \n",
    "    def save(self,fileName):\n",
    "        outfile = open(fileName,'wb')\n",
    "        pickle.dump(self, outfile)\n",
    "        outfile.close()\n",
    "        \n",
    "    @classmethod\n",
    "    def load(self, fileName):\n",
    "        infile = open(fileName,'rb')\n",
    "        print(fileName)\n",
    "        new_dict = pickle.load(infile)\n",
    "        infile.close()\n",
    "        return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f05cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2)\n"
     ]
    }
   ],
   "source": [
    "n_features=6\n",
    "#coefficients=['cHQ3', 'cHW', 'cHWtil']\n",
    "#base_points = np.asarray([np.array([1, value1, value2, value3]) for value1 in [-1.5, -.8, .2, 0., .2, .8, 1.5]  for value2 in [-1.5, -.8, .2, 0, .2, .8, 1.5] for value3 in [-1.5, -.8, .2, 0, .2, .8, 1.5]])\n",
    "#coefficients=['cHW', 'cHWtil']\n",
    "#base_points = np.asarray([np.array([1, value1, value2]) for value1 in [-1.5, -.8, .2, 0., .2, .8, 1.5]  for value2 in [-1.5, -.8, .2, 0, .2, .8, 1.5]])\n",
    "coefficients=['cHQ3']\n",
    "base_points = np.asarray([np.array([1, value1]) for value1 in [-1.5, -.8, .2, 0., .2, .8, 1.5]])\n",
    "print(base_points.shape)\n",
    "r_NN = R(n_features, coefficients)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8e3dc7-f2ba-4849-9d50-1bf07fa46b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_directory=\"v1_with_Biasing\"\n",
    "\n",
    "nEvents=30000\n",
    "learning_rate = 1e-3\n",
    "device        = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_epoch       = 10000\n",
    "plot_every    = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a181dfe7-810d-4711-a6cd-2bdc69654ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested 30000 events. Simulated 30000 events and 30000 survive pT_min cut of 0.\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "import ZH_Nakamura \n",
    "ZH_Nakamura.feature_names = ZH_Nakamura.feature_names[0:6] # restrict features\n",
    "features   = ZH_Nakamura.getEvents(nEvents)[:,0:6]\n",
    "feature_names  = ZH_Nakamura.feature_names\n",
    "plot_options   = ZH_Nakamura.plot_options\n",
    "plot_vars      = ZH_Nakamura.feature_names\n",
    "\n",
    "mask       = (features[:,feature_names.index('pT')]<900) & (features[:,feature_names.index('sqrt_s_hat')]<1800) \n",
    "features = features[mask]\n",
    "\n",
    "n_features = len(features[0])\n",
    "weights    = ZH_Nakamura.getWeights(features, ZH_Nakamura.make_eft())\n",
    "\n",
    "\n",
    "pT=features[:,feature_names.index('pT')]\n",
    "features=torch.from_numpy(features)\n",
    "#for key,value in weights.items():\n",
    " #   value*=bias_factor\n",
    "  #  weights[key]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42481a4e-fa28-4a93-b413-2d085ac01cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params=[]\n",
    "for comb in r_NN.combination_list:\n",
    "        all_params+=r_NN.n_hat[comb].parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79bce9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(list(all_params), lr=learning_rate)\n",
    "losses = []\n",
    "for comb in r_NN.combination_list:\n",
    "    r_NN.n_hat[comb].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0984cc6-b355-4e3e-bec0-3020b124d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99 loss 0.7530355253884699\n",
      "Loss:\n",
      "tensor(0.7530, grad_fn=<SumBackward0>)\n",
      "epoch 199 loss 0.7383465722702608\n",
      "Loss:\n",
      "tensor(0.7383, grad_fn=<SumBackward0>)\n",
      "epoch 299 loss 0.7178787652048446\n",
      "Loss:\n",
      "tensor(0.7179, grad_fn=<SumBackward0>)\n",
      "epoch 399 loss 0.7042320116241736\n",
      "Loss:\n",
      "tensor(0.7042, grad_fn=<SumBackward0>)\n",
      "epoch 499 loss 0.6863276835743011\n",
      "Loss:\n",
      "tensor(0.6863, grad_fn=<SumBackward0>)\n",
      "epoch 599 loss 0.638567328440903\n",
      "Loss:\n",
      "tensor(0.6386, grad_fn=<SumBackward0>)\n",
      "epoch 699 loss 0.6350074084181669\n",
      "Loss:\n",
      "tensor(0.6350, grad_fn=<SumBackward0>)\n",
      "epoch 799 loss 0.634416085520451\n",
      "Loss:\n",
      "tensor(0.6344, grad_fn=<SumBackward0>)\n",
      "epoch 899 loss 0.6338122377437175\n",
      "Loss:\n",
      "tensor(0.6338, grad_fn=<SumBackward0>)\n",
      "epoch 999 loss 0.6331632260006564\n",
      "Loss:\n",
      "tensor(0.6332, grad_fn=<SumBackward0>)\n",
      "epoch 1099 loss 0.6327114354714574\n",
      "Loss:\n",
      "tensor(0.6327, grad_fn=<SumBackward0>)\n",
      "epoch 1199 loss 0.6323133815768558\n",
      "Loss:\n",
      "tensor(0.6323, grad_fn=<SumBackward0>)\n",
      "epoch 1299 loss 0.6319494458852626\n",
      "Loss:\n",
      "tensor(0.6319, grad_fn=<SumBackward0>)\n",
      "epoch 1399 loss 0.6315408917787364\n",
      "Loss:\n",
      "tensor(0.6315, grad_fn=<SumBackward0>)\n",
      "epoch 1499 loss 0.6308993387201385\n",
      "Loss:\n",
      "tensor(0.6309, grad_fn=<SumBackward0>)\n",
      "epoch 1599 loss 0.6303131234641344\n",
      "Loss:\n",
      "tensor(0.6303, grad_fn=<SumBackward0>)\n",
      "epoch 1699 loss 0.6296615005908913\n",
      "Loss:\n",
      "tensor(0.6297, grad_fn=<SumBackward0>)\n",
      "epoch 1799 loss 0.6288150344030727\n",
      "Loss:\n",
      "tensor(0.6288, grad_fn=<SumBackward0>)\n",
      "epoch 1899 loss 0.6277443586497107\n",
      "Loss:\n",
      "tensor(0.6277, grad_fn=<SumBackward0>)\n",
      "epoch 1999 loss 0.6250926675904751\n",
      "Loss:\n",
      "tensor(0.6251, grad_fn=<SumBackward0>)\n",
      "epoch 2099 loss 0.6244095494648887\n",
      "Loss:\n",
      "tensor(0.6244, grad_fn=<SumBackward0>)\n",
      "epoch 2199 loss 0.6242104586522046\n",
      "Loss:\n",
      "tensor(0.6242, grad_fn=<SumBackward0>)\n",
      "epoch 2299 loss 0.6240607284497361\n",
      "Loss:\n",
      "tensor(0.6241, grad_fn=<SumBackward0>)\n",
      "epoch 2399 loss 0.623887900291713\n",
      "Loss:\n",
      "tensor(0.6239, grad_fn=<SumBackward0>)\n",
      "epoch 2499 loss 0.6236096791228416\n",
      "Loss:\n",
      "tensor(0.6236, grad_fn=<SumBackward0>)\n",
      "epoch 2599 loss 0.6235145753186837\n",
      "Loss:\n",
      "tensor(0.6235, grad_fn=<SumBackward0>)\n",
      "epoch 2699 loss 0.6234436279138797\n",
      "Loss:\n",
      "tensor(0.6234, grad_fn=<SumBackward0>)\n",
      "epoch 2799 loss 0.6234015949645766\n",
      "Loss:\n",
      "tensor(0.6234, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    loss = f_loss(r_NN,features,torch.from_numpy(base_points),weights)\n",
    "    \n",
    "    if epoch % 100 == 99:\n",
    "        print(\"epoch\", epoch, \"loss\",  loss.item())\n",
    "        print(\"Loss:\")\n",
    "        print(loss)\n",
    "        \n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce570a5-93de-4072-a0bd-3b26c1b366e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b000a2-0920-4deb-8b7f-e4995f773c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-ptur]",
   "language": "python",
   "name": "conda-env-conda-ptur-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
